{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 9)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 12)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 8)\t1\n",
      "  (2, 12)\t1\n",
      "  (2, 11)\t1\n",
      "  (2, 10)\t1\n",
      "  (2, 1)\t1\n"
     ]
    }
   ],
   "source": [
    "#Text Classification\n",
    "#feature extraction\n",
    "#count vectorization: will form a DTM of the features/words in a text/string\n",
    "\n",
    "messages= ['Hey, lets go to the game toaay!', 'Call your friends', 'want to go walk your dogs?']\n",
    "#we'll use sklearn and not spacy for count vectorization\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()\n",
    "dtm= vect.fit_transform(messages)\n",
    "print(dtm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 9)\t0.40301621080355077\n",
      "  (0, 3)\t0.40301621080355077\n",
      "  (0, 7)\t0.40301621080355077\n",
      "  (0, 8)\t0.3065042162415877\n",
      "  (0, 4)\t0.3065042162415877\n",
      "  (0, 6)\t0.40301621080355077\n",
      "  (0, 5)\t0.40301621080355077\n",
      "  (1, 2)\t0.6227660078332259\n",
      "  (1, 12)\t0.4736296010332684\n",
      "  (1, 0)\t0.6227660078332259\n",
      "  (2, 1)\t0.45954803293870056\n",
      "  (2, 10)\t0.45954803293870056\n",
      "  (2, 11)\t0.45954803293870056\n",
      "  (2, 12)\t0.3494981241087058\n",
      "  (2, 8)\t0.3494981241087058\n",
      "  (2, 4)\t0.3494981241087058\n"
     ]
    }
   ],
   "source": [
    "#we also have tfidvectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect= TfidfVectorizer()\n",
    "dtm= vect.fit_transform(messages)\n",
    "print(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "      <th>punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message  length  punct\n",
       "0   ham  Go until jurong point, crazy.. Available only ...     111      9\n",
       "1   ham                      Ok lar... Joking wif u oni...      29      6\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...     155      6\n",
       "3   ham  U dun say so early hor... U c already then say...      49      6\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...      61      2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#text preprocessing, stopwords removal, tokenization all included in count vectorizer\n",
    "#TfidfVectorizer combines the CountVectorizer and TfidfTransformer\n",
    "#we're gonna use a pipeline to determine whether a text is 'spam' or 'ham'\n",
    "#the pipeline has 2 steps, first is TfidfVectorizer and the second is to train our LinearSVC model\n",
    "\n",
    "import pandas as pd\n",
    "df= pd.read_csv('./smsspamcollection.tsv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157                           I'm leaving my house now...\n",
       "3436    Hi darlin i cantdo anythingtomorrow as myparen...\n",
       "4401                      Juz go google n search 4 qet...\n",
       "1686                  Cramps stopped. Going back to sleep\n",
       "883     I love to give massages. I use lots of baby oi...\n",
       "                              ...                        \n",
       "19      England v Macedonia - dont miss the goals/team...\n",
       "544       4 oclock at mine. Just to bash out a flat plan.\n",
       "1926    We don call like  &lt;#&gt;  times oh. No give...\n",
       "1368    I don't know, same thing that's wrong everyso ...\n",
       "1531                        I think chennai well settled?\n",
       "Name: message, Length: 4179, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X= df['message']\n",
    "y=df['label']\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we build the pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "text_clf= Pipeline([('tfidf', TfidfVectorizer()),('clf', LinearSVC())])\n",
    "text_clf.fit(X_train, y_train)\n",
    "predictions= text_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1199    2]\n",
      " [  17  175]] \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      0.99      1201\n",
      "        spam       0.99      0.91      0.95       192\n",
      "\n",
      "    accuracy                           0.99      1393\n",
      "   macro avg       0.99      0.95      0.97      1393\n",
      "weighted avg       0.99      0.99      0.99      1393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,predictions), '\\n', classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict(['hey how are you doing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict(['congratulatons, you have won $6 million. call us at 12:00'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.predict(['you have won 1 million dollars, please call our office to receive it'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
